{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulator: Artificial Neural Network (scikit-learn)\n",
    "\n",
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import packages](#imports)\n",
    "2. [Load data](#loadData)\n",
    "    1. [Load train data](#loadTrainData)\n",
    "    2. [Load test data](#loadTestData)\n",
    "3. [Emulator method](#emulator)\n",
    "    1. [Scale data](#scaleData)\n",
    "    2. [Train emulator](#trainEmu)\n",
    "    3. [Predict on test data](#predEmu)\n",
    "    4. [Plot results](#plotEmu)\n",
    "\n",
    "## 1. Import packages<a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import pylab\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "matplotlib.rcParams['figure.dpi'] = 80\n",
    "textsize = 'x-large'\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (5, 4),\n",
    "         'axes.labelsize': textsize,\n",
    "         'axes.titlesize': textsize,\n",
    "         'xtick.labelsize': textsize,\n",
    "         'ytick.labelsize': textsize}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data<a name=\"loadData\"></a>\n",
    "\n",
    "### 2.1. Load train data<a name=\"loadTrainData\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set here is the correlation function of galaxy clustering, for different cosmological model. Here we show a 3-free-parameter model; you can also play with a simpler 1-free-parameter model by commenting in the '1d' data (be sure to do this with the test set too). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '../data/cosmology_train_big.pickle'\n",
    "#path_train = '../data/cosmology_train.pickle'\n",
    "#path_train = '../data/cosmology_train_1d.pickle'\n",
    "with open(path_train, 'rb') as input_file:\n",
    "    data_train = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = data_train['input_data']\n",
    "number_train = input_train.shape[0]\n",
    "print(\"Number of datapoints:\", number_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train = data_train['output_data']\n",
    "n_params = input_train.shape[1]-1\n",
    "n_values = output_train.shape[1]-1\n",
    "print(\"Number of input parameters:\", n_params)  # remove the `object_id` column\n",
    "print(\"Number of output values:\", n_values)  # remove the `object_id` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train = np.array(input_train.drop(columns=['object_id']))\n",
    "ys_train = np.array(output_train.drop(columns=['object_id']))\n",
    "extra_train = data_train['extra_input']\n",
    "r_vals = extra_train['r_vals']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load test data<a name=\"loadTestData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '../data/cosmology_test.pickle'\n",
    "#path_test = '../data/cosmology_test_1d.pickle'\n",
    "with open(path_test, 'rb') as input:\n",
    "    data_test = pickle.load(input)\n",
    "input_test = data_test['input_data']\n",
    "number_test = input_test.shape[0]\n",
    "print(\"Number of datapoints:\", number_test)\n",
    "output_test = data_test['output_data']\n",
    "print(\"Number of input parameters:\", input_test.shape[1]-1)  # remove the `object_id` column\n",
    "print(\"Number of output values:\", output_test.shape[1]-1)  # remove the `object_id` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test = np.array(input_test.drop(columns=['object_id']))\n",
    "ys_test = np.array(output_test.drop(columns=['object_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Emulator method<a name=\"emulator\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Scale data<a name=\"scaleData\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first scale our input parameters, to make training easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(xs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train = scaler.transform(xs_train)\n",
    "xs_test = scaler.transform(xs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also normalize the output data by the mean of the training data, so it's easier to emulate (don't forget to undo the normalization after!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = np.mean(ys_train, axis=0)\n",
    "ys_train = ys_train/y_mean\n",
    "ys_test = ys_test/y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Train emulator<a name=\"trainEmu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `scikit-learn`'s `MLPRegressor` to build our emulator. We train a separate regressor for each output value. \n",
    "\n",
    "For this dataset, the simple 'lbfgs' solver works very well. We can also use the 'adam' optimizer; in both cases, we have to tune the hyperparameters carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrs = np.empty(n_values, dtype=object)\n",
    "for j in range(n_values):\n",
    "    ys_train_r = ys_train[:,j]\n",
    "    ys_test_r = ys_test[:,j]\n",
    "    regr = MLPRegressor(hidden_layer_sizes=(14, ), alpha=0.00028, activation='relu',\n",
    "                        random_state=1, max_iter=10000, solver='lbfgs', tol=1e-6\n",
    "                       ).fit(xs_train, ys_train_r)\n",
    "    score = regr.score(xs_test, ys_test_r)\n",
    "    print(f\"Value {j} score:\", score)\n",
    "    regrs[j] = regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values should be as close to 1 as possible. Try tuning the hyperparameters (the hidden layer sizes and alpha, mainly) to get better results on your test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Predict on test data<a name=\"predEmu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict on our test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_predict = np.zeros((number_test, n_values))\n",
    "for j in range(n_values):  \n",
    "    ys_predict_r = regrs[j].predict(xs_test)\n",
    "    ys_predict[:,j] = ys_predict_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undo all the normalizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_train = ys_train*y_mean\n",
    "ys_test = ys_test*y_mean\n",
    "ys_predict = ys_predict*y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Plot results<a name=\"plotEmu\"></a>\n",
    "\n",
    "We compare our predictions to the truth (choosing a subset for visual clarity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = int(0.2*number_test)\n",
    "idxs = np.random.choice(np.arange(number_test), n_plot)\n",
    "color_idx = np.linspace(0, 1, n_plot)\n",
    "colors = np.array([plt.cm.rainbow(c) for c in color_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i in range(n_plot):\n",
    "    ys_test_plot = ys_test[idxs,:][i]\n",
    "    ys_predict_plot = ys_predict[idxs][i]\n",
    "    if i==0:\n",
    "        label_test = 'truth'\n",
    "        label_predict = 'emu_prediction'\n",
    "    else:\n",
    "        label_test = None\n",
    "        label_predict = None\n",
    "    plt.plot(r_vals[:n_values], ys_test_plot, alpha=0.8, label=label_test, marker='o', markerfacecolor='None', ls='None', color=colors[i])\n",
    "    plt.plot(r_vals[:n_values], ys_predict_plot, alpha=0.8, label=label_predict, color=colors[i])\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel(r'$\\xi(r)$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i in range(n_plot):\n",
    "    ys_test_plot = ys_test[idxs,:][i]\n",
    "    ys_predict_plot = ys_predict[idxs][i]\n",
    "    frac_err = (ys_predict_plot-ys_test_plot)/ys_test_plot\n",
    "    plt.plot(r_vals, frac_err, alpha=0.8, color=colors[i])\n",
    "plt.axhline(0.0, color='k')\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel(r'fractional error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Our emulator predicts most statistics with <2% accuracy, with just a few outliers, and those are still within 12%.\n",
    "\n",
    "[Go back to top.](#index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
