{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulator: Celerite\n",
    "\n",
    "This notebook provides a template to build an emulator with [Celerite](https://celerite.readthedocs.io/en/stable/). \n",
    "\n",
    "There are many Gaussian process (GP) Python libraries that are commonly used to solve regression problems. The two we used here are [Celerite](https://celerite.readthedocs.io/en/stable/) and [George](https://george.readthedocs.io/en/latest/). Both of these libraries use a kernel-based, Bayesian method of regression. A visual exploration of GPs can be found [A Visual Exploration of Gaussian Processes](https://distill.pub/2019/visual-exploration-gaussian-processes/) and a more complete theory behind GPs can be found for free at [ Rasmussen & Williams (2006)](http://www.gaussianprocess.org/gpml/)\n",
    "\n",
    "The basic idea behind GPs is to use Gaussian distributions (also referred to as *normal* distributions), defined by a mean vector and a covariance matrix (also called kernel), to predict a function at certain *test* points. Each GP library has their own choise of built-in kernels and the option to build your own. The choice of kernel can make a big difference on the success of the regression and finding the best kernel for your own dataset is a bit of an art. Each GP library also has their own strengths and limitations. In terms of using them as emulators we found that George provides good regression models, is able to build GP regressors in 2 or 3 dimensions, but it takes a long time to emulate. Celerite on the other hand is a very fast way to build regressors but it is limited to 1 dimension and is not very accurate in fitting datasets with multiple inputs. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import packages](#imports)\n",
    "2. [Load data](#loadData)\n",
    "    1. [Load train data](#loadTrainData)\n",
    "    2. [Load test data](#loadTestData)\n",
    "3. [Emulator method](#emulator)\n",
    "    1. [Scale data](#scaleData)\n",
    "    2. [Train emulator](#trainEmu)\n",
    "    3. [Plot results](#plotEmu)\n",
    "\n",
    "## 1. Import packages<a name=\"imports\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import celerite\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as op\n",
    "import seaborn as sns\n",
    "\n",
    "from celerite import terms\n",
    "from matplotlib import pylab\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aesthetic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set(font_scale=1.3, style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data<a name=\"loadData\"></a>\n",
    "\n",
    "Read the training data from a `.pickle` file:\n",
    "\n",
    "### 2.1. Load training data<a name=\"loadTrainData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '../data/cosmology_train_1d.pickle'\n",
    "with open(path_train, 'rb') as input_file:\n",
    "    data_train = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = data_train['input_data']\n",
    "output_train = data_train['output_data']\n",
    "number_train = input_train.shape[0]\n",
    "number_param = input_train.shape[1] - 1\n",
    "number_outputs = output_train.shape[1] - 1\n",
    "print(\"Number of datapoints:\", number_train)\n",
    "print(\"Number of input parameters:\", number_param) # remove the `object_id` column\n",
    "print(\"Number of outputs:\", number_outputs) # remove the `object_id` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_train = data_train['extra_input']\n",
    "r_vals = extra_train['r_vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train = input_train.drop(columns=['object_id'])\n",
    "ys_train = output_train.drop(columns=['object_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load test data<a name=\"loadTrainData\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '../data/cosmology_test_1d.pickle'\n",
    "with open(path_test, 'rb') as input:\n",
    "    data_test = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = data_test['input_data']\n",
    "output_test = data_test['output_data']\n",
    "number_test = input_test.shape[0]\n",
    "print(\"Number of datapoints:\", number_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test = input_test.drop(columns=['object_id'])\n",
    "ys_test = output_test.drop(columns=['object_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Emulator method<a name=\"emulator\"></a>\n",
    "\n",
    "### 3.1. Scale data<a name=\"scaleData\"></a>\n",
    "\n",
    "Let's first scale our input parameters, to make training easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(xs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train.iloc[:] = scaler.transform(xs_train)\n",
    "xs_test.iloc[:] = scaler.transform(xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = np.mean(ys_train, axis=0)\n",
    "ys_train = ys_train/y_mean\n",
    "ys_test = ys_test/y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Train emulator<a name=\"trainEmu\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gp(kernel, x, y, x_new):\n",
    "    \n",
    "    x = x.iloc[:,0]\n",
    "    x_new = x_new.iloc[:,0]\n",
    "    \n",
    "    def neg_log_like(params,y,gp): \n",
    "        gp.set_parameter_vector(params)\n",
    "        loglike = gp.log_likelihood(y)\n",
    "        return -loglike if np.isfinite(loglike) else 1e25\n",
    "\n",
    "    def grad_neg_log_like(params, y, gp):\n",
    "        gp.set_parameter_vector(params)\n",
    "        return -gp.grad_log_likelihood(y)[1]\n",
    "    \n",
    "    \n",
    "    gp = celerite.GP(kernel, mean=0, fit_mean=False)\n",
    "    gp.compute(x)\n",
    "    #print(\"Initial log-likelihood: {0}\".format(gp.log_likelihood(y)))\n",
    "    \n",
    "    # Fit for the maximum likelihood parameters\n",
    "    bounds = gp.get_parameter_bounds()\n",
    "    results = op.minimize(neg_log_like, gp.get_parameter_vector(), \n",
    "                       jac=grad_neg_log_like, args=(y, gp))\n",
    "    gp.set_parameter_vector(results.x)\n",
    "    #print(\"Final log-likelihood: {0}\".format(-results.fun))\n",
    "\n",
    "    # Make the maximum likelihood prediction\n",
    "    gp_mean, gp_cov = gp.predict(y, x_new, return_var=True)\n",
    "    std = np.sqrt(gp_cov)\n",
    "    \n",
    "    return gp_mean, gp_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_outputs = np.shape(ys_test)[1]\n",
    "print(number_outputs)\n",
    "ys_test_preds = ys_test.copy()\n",
    "ys_train_0 = ys_train.iloc[:, 0]\n",
    "for i in np.arange(number_outputs):\n",
    "    print(i)\n",
    "    ys_train_i = ys_train.iloc[:, i]\n",
    "    \n",
    "    term1 = terms.RealTerm(-1, 8.5)\n",
    "    term2 = terms.JitterTerm(log_sigma=10)\n",
    "    term3 = terms.RealTerm(log_a=np.log(np.var(ys_train_i)+5), log_c=-np.log(5.0))\n",
    "    term4 = terms.RealTerm(np.exp(np.var(ys_train_0)), -2)\n",
    "\n",
    "    # Try different kernels \n",
    "    kernel = term1\n",
    "    ys_pred, ys_cov = fit_gp(kernel=kernel, x=xs_train, \n",
    "                             y=ys_train_i, x_new=xs_test)\n",
    "    ys_test_preds.iloc[:, i] = ys_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undo all the normalizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_test = ys_test*y_mean\n",
    "ys_test_preds = ys_test_preds*y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Plot results<a name=\"plotEmu\"></a>\n",
    "\n",
    "We compare our predictions to the truth (choosing a subset for visual clarity). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "n_plot = int(0.2*number_test)\n",
    "idxs = np.random.choice(np.arange(number_test), n_plot)\n",
    "color_idx = np.linspace(0, 1, n_plot)\n",
    "colors = np.array([plt.cm.rainbow(c) for c in color_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i in range(n_plot):\n",
    "    ys_test_i = ys_test.iloc[idxs[i], :]\n",
    "    ys_pred_i = ys_test_preds.iloc[idxs[i], :]\n",
    "    if i==0:\n",
    "        label_test = 'truth'\n",
    "        label_pred = 'emu_prediction'\n",
    "    else:\n",
    "        label_test = None\n",
    "        label_pred = None\n",
    "    plt.plot(r_vals, ys_test_i, alpha=0.8, label=label_test, \n",
    "             marker='o', markerfacecolor='None', ls='None', color=colors[i])\n",
    "    plt.plot(r_vals, ys_pred_i, alpha=0.8, label=label_pred, color=colors[i])\n",
    "plt.xlabel('$r$')\n",
    "# plt.ylim(-.001,0.015)\n",
    "plt.ylabel(r'$\\xi(r)$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the fractional error of all test set statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_idx = np.linspace(0, 1, number_test)\n",
    "colors = np.array([plt.cm.rainbow(c) for c in color_idx])\n",
    "plt.figure(figsize=(8,6))\n",
    "frac_errs = np.empty((number_test, number_outputs))\n",
    "for i in range(number_test):\n",
    "    ys_test_i = ys_test.iloc[i, :]\n",
    "    ys_pred_i = ys_test_preds.iloc[i, :]\n",
    "    frac_err = (ys_pred_i-ys_test_i)/ys_test_i\n",
    "    frac_errs[i] = frac_err\n",
    "    plt.plot(r_vals, frac_err, alpha=0.8, color=colors[i])\n",
    "plt.axhline(0.0, color='k')\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel(r'fractional error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the spread of these fractional errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i in range(n_plot):\n",
    "    ys_test_i = ys_test.iloc[idxs[i], :]\n",
    "    ys_pred_i = ys_test_preds.iloc[idxs[i], :]\n",
    "    frac_err = (ys_pred_i-ys_test_i)/ys_test_i\n",
    "    plt.plot(r_vals, frac_err, alpha=0.8, color=colors[i])\n",
    "plt.axhline(0.0, color='k')\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel(r'fractional error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
