{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulator: Gaussian Process (`george`)\n",
    "\n",
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import packages](#imports)\n",
    "2. [Load data](#loadData)\n",
    "    1. [Load train data](#loadTrainData)\n",
    "    2. [Load test data](#loadTestData)\n",
    "3. [Emulator method](#emulator)\n",
    "    1. [Scale data](#scaleData)\n",
    "    2. [Train emulator](#trainEmu)\n",
    "    3. [Plot results](#plotEmu)\n",
    "\n",
    "## 1. Import packages<a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import george\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.optimize as op\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aesthetic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set(font_scale=1.3, style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data<a name=\"loadData\"></a>\n",
    "\n",
    "Read the training data from a `.npy` file:\n",
    "\n",
    "### 2.1. Load train data<a name=\"loadTrainData\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the full demo, we'll use 1d data (a single input parameter/feature), but you can also try it the full 3d data; this just takes a long time to train, so you might want to load in our already saved results below to view it. Remember to load in the corresponding test data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '../data/cosmology_train_1d.pickle'\n",
    "#path_train = '../data/cosmology_train.pickle'\n",
    "#path_train = '../data/cosmology_train_big.pickle'\n",
    "with open(path_train, 'rb') as input_file:\n",
    "    data_train = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = data_train['input_data']\n",
    "output_train = data_train['output_data']\n",
    "number_train = input_train.shape[0]\n",
    "number_param = input_train.shape[1] - 1\n",
    "n_values = output_train.shape[1]-1\n",
    "print(\"Number of datapoints:\", number_train)\n",
    "print(\"Number of input parameters:\", number_param) # remove the `object_id` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_train = data_train['extra_input']\n",
    "r_vals = extra_train['r_vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train = input_train.drop(columns=['object_id'])\n",
    "ys_train = output_train.drop(columns=['object_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load test data<a name=\"loadTestData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '../data/cosmology_test_1d.pickle'\n",
    "#path_test = '../data/cosmology_test.pickle'\n",
    "with open(path_test, 'rb') as input_file:\n",
    "    data_test = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = data_test['input_data']\n",
    "output_test = data_test['output_data']\n",
    "number_test = input_test.shape[0]\n",
    "print(\"Number of datapoints:\", number_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test = input_test.drop(columns=['object_id'])\n",
    "ys_test = output_test.drop(columns=['object_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Emulator method<a name=\"emulator\"></a>\n",
    "\n",
    "### 3.1. Scale data<a name=\"scaleData\"></a>\n",
    "\n",
    "Let's first scale our input parameters, to make training easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(xs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train.iloc[:] = scaler.transform(xs_train)\n",
    "xs_test.iloc[:] = scaler.transform(xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = np.mean(ys_train, axis=0)\n",
    "ys_train = ys_train/y_mean\n",
    "ys_test = ys_test/y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Train emulator<a name=\"trainEmu\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gp(kernel, xs, ys, xs_new):\n",
    "    \n",
    "    def neg_log_like(p):  # Objective function: negative log-likelihood\n",
    "        gp.set_parameter_vector(p)\n",
    "        loglike = gp.log_likelihood(ys, quiet=True)\n",
    "        return -loglike if np.isfinite(loglike) else 1e25\n",
    "\n",
    "    def grad_neg_log_like(p):  # Gradient of the objective function.\n",
    "        gp.set_parameter_vector(p)\n",
    "        return -gp.grad_log_likelihood(ys, quiet=True)\n",
    "    \n",
    "    gp = george.GP(kernel)\n",
    "    gp.compute(xs)\n",
    "    results = op.minimize(neg_log_like, gp.get_parameter_vector(),\n",
    "                          jac=grad_neg_log_like, method=\"L-BFGS-B\", tol=1e-6)\n",
    "    \n",
    "    gp.set_parameter_vector(results.x)\n",
    "    gp_mean, gp_cov = gp.predict(ys, xs_new)\n",
    "    return gp_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to train and predict the value straight away. (If you're loading in saved results, comment out the next 2 cells.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_outputs = np.shape(ys_test)[1]\n",
    "print(number_outputs)\n",
    "ys_test_preds = ys_test.copy()\n",
    "ys_train_0 = ys_train.iloc[:, 0]\n",
    "for i in np.arange(number_outputs):\n",
    "    print(i)\n",
    "    ys_train_i = ys_train.iloc[:, i]\n",
    "    kernel = np.var(ys_train_0) * george.kernels.ExpSquaredKernel(0.5, ndim=number_param)\n",
    "    ys_pred = fit_gp(kernel=kernel, xs=xs_train, \n",
    "                     ys=ys_train_i, xs_new=xs_test)\n",
    "    ys_test_preds.iloc[:, i] = ys_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undo all the normalizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_test = ys_test*y_mean\n",
    "ys_test_preds = ys_test_preds*y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results. (Commented out as results have already been saved.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save_results = f'emulator_results/output_pred_big_train_{number_param}d.pickle'\n",
    "#ys_test_preds.to_pickle(path_save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the results were well saved. (If you're looking at the 3d data, you'll want to load this in here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ys_test_preds_saved = pd.read_pickle(path_save_results)\n",
    "#np.allclose(ys_test_preds_saved, ys_test_preds)\n",
    "#ys_test_preds = ys_test_preds_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Plot results<a name=\"plotEmu\"></a>\n",
    "\n",
    "We compare our predictions to the truth (choosing a subset for visual clarity). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = int(0.2*number_test)\n",
    "idxs = np.random.choice(np.arange(number_test), n_plot)\n",
    "color_idx = np.linspace(0, 1, n_plot)\n",
    "colors = np.array([plt.cm.rainbow(c) for c in color_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i in range(n_plot):\n",
    "    ys_test_i = ys_test.iloc[idxs[i], :]\n",
    "    ys_pred_i = ys_test_preds.iloc[idxs[i], :]\n",
    "    if i==0:\n",
    "        label_test = 'truth'\n",
    "        label_pred = 'emu_prediction'\n",
    "    else:\n",
    "        label_test = None\n",
    "        label_pred = None\n",
    "    plt.plot(r_vals, ys_test_i, alpha=0.8, label=label_test, \n",
    "             marker='o', markerfacecolor='None', ls='None', color=colors[i])\n",
    "    plt.plot(r_vals, ys_pred_i, alpha=0.8, label=label_pred, color=colors[i])\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel(r'$\\xi(r)$')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the fractional error of all test set statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_idx = np.linspace(0, 1, number_test)\n",
    "colors = np.array([plt.cm.rainbow(c) for c in color_idx])\n",
    "plt.figure(figsize=(8,6))\n",
    "frac_errs = np.empty((number_test, n_values))\n",
    "for i in range(number_test):\n",
    "    ys_test_i = ys_test.iloc[i, :]\n",
    "    ys_pred_i = ys_test_preds.iloc[i, :]\n",
    "    frac_err = (ys_pred_i-ys_test_i)/ys_test_i\n",
    "    frac_errs[i] = frac_err\n",
    "    plt.plot(r_vals, frac_err, alpha=0.8, color=colors[i])\n",
    "plt.axhline(0.0, color='k')\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel(r'fractional error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the spread of these fractional errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_idx = np.linspace(0, 1, number_test)\n",
    "colors = np.array([plt.cm.rainbow(c) for c in color_idx])\n",
    "plt.figure(figsize=(8,6))\n",
    "frac_errs_stdev = np.std(frac_errs, axis=0)\n",
    "plt.plot(r_vals, frac_errs_stdev, alpha=0.8, color='blue', label='standard deviation')\n",
    "\n",
    "frac_errs_p16 = np.percentile(frac_errs, 16, axis=0)\n",
    "frac_errs_p84 = np.percentile(frac_errs, 84, axis=0)\n",
    "frac_errs_percentile = np.mean([np.abs(frac_errs_p16), np.abs(frac_errs_p84)], axis=0)\n",
    "plt.plot(r_vals, frac_errs_percentile, alpha=0.8, color='green', label=\"mean of 16/84 percentile\")\n",
    "\n",
    "\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel(r'spread of fractional errors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GP is doing incredibly well at accurately emulating the correlation function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
