{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulator: Support Vector Machine (scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows the emulation of the two point correlation functions using Suport Vector Machine (SVM).\n",
    "\n",
    "SVM is a supervised learning algorithm that can be employed in classification and regression tasks. In particular, in this notebook uses SVM for regression analysis purposes. \n",
    "\n",
    "The Support Vector Regression (SVR) uses the same principles as the SVM for classification, with only a few minor differences. A margin is defined not to separate between two classes but instead is used to define the region of intereset ($\\epsilon$).\n",
    "\n",
    "![../images/svr.png](../images/svr.png)\n",
    "\n",
    "The main idea is: to minimize error, individualizing the hyperplane which maximizes the margin, keeping in mind that part of the error is tolerated.  \n",
    "\n",
    "Usually, SVM is better in small sample than the other methods.\n",
    "\n",
    "for more information: https://www.saedsayad.com/support_vector_machine_reg.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import packages](#imports)\n",
    "2. [Load data](#loadData)\n",
    "    1. [Load train data](#loadTrainData)\n",
    "    2. [Load test data](#loadTestData)\n",
    "3. [Visualize dataset](#visualizeData)\n",
    "    1. [Data structure](#dataStructure)\n",
    "    2. [Plot datasets](#plotData)\n",
    "4. [Emulator method](#emulator)\n",
    "    1. [Scale data](#scaleData)\n",
    "    2. [Train emulator](#trainEmu)\n",
    "    3. [Predict on test data](#predEmu)\n",
    "    4. [Plot results](#plotEmu)\n",
    "    5. [Improving the emulator](#improveEmu)\n",
    "\n",
    "## 1. Import packages<a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data<a name=\"loadData\"></a>\n",
    "\n",
    "Read the training data from a `.npy` file:\n",
    "\n",
    "### 2.1. Load train data<a name=\"loadTrainData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('../data/cosmology_train.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosmology dataset contains cosmological parameters (Omega_m, sigma8, Omega_b) as inputs, and the correlation function as output. The correlation function is measured at 10 separation values $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load test data<a name=\"loadTestData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_pickle('../data/cosmology_test.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing the dataset<a name=\"visualizeData\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Structure<a name=\"dataStructure\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosmology dataset contains cosmological parameters (Omega_m, sigma8, Omega_b) as inputs, and the correlation function as output. The correlation function is measured at 10 separation values  ùëü ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = df['input_data']\n",
    "df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df['output_data']\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvals = df['extra_input']['r_vals']\n",
    "rvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_train = df_out[[r'$\\xi(r_0)$', r'$\\xi(r_1)$', r'$\\xi(r_2)$', r'$\\xi(r_3)$',\n",
    "       r'$\\xi(r_4)$', r'$\\xi(r_5)$', r'$\\xi(r_6)$', r'$\\xi(r_7)$', r'$\\xi(r_8)$',\n",
    "       r'$\\xi(r_9)$']].to_numpy()\n",
    "\n",
    "xs_train = df_in[[r'$\\Omega_m$', r'$\\sigma_8$', r'$\\Omega_b$']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x shape:',xs_train.shape)\n",
    "print('y shape:',ys_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plot datasets<a name=\"plotData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "ys_train_plot = ys_train.copy()\n",
    "np.random.shuffle(ys_train_plot) # shuffle so that color order isn't weird\n",
    "plt.plot(rvals, ys_train_plot.T, alpha=0.8)\n",
    "\n",
    "plt.xlabel('$r$',fontsize=18)\n",
    "plt.ylabel(r'$\\xi(r)$',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_in = df_test['input_data']\n",
    "df_test_out = df_test['output_data']\n",
    "\n",
    "ys_test = df_test_out[[r'$\\xi(r_0)$', r'$\\xi(r_1)$', r'$\\xi(r_2)$', r'$\\xi(r_3)$',\n",
    "       r'$\\xi(r_4)$', r'$\\xi(r_5)$', r'$\\xi(r_6)$', r'$\\xi(r_7)$', r'$\\xi(r_8)$',\n",
    "       r'$\\xi(r_9)$']].to_numpy()\n",
    "\n",
    "xs_test = df_test_in[[r'$\\Omega_m$', r'$\\sigma_8$', r'$\\Omega_b$']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = xs_test.shape[0]\n",
    "n_values= ys_test.shape[1]\n",
    "n_params= xs_test.shape[1]\n",
    "print(\"Number of datapoints:\", n_test)\n",
    "print(\"Number of input parameters:\", n_params)\n",
    "print(\"Number of output values:\", n_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(rvals, ys_test.T, alpha=0.8)\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel(r'$\\xi(r)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Emulator method<a name=\"emulator\"></a>\n",
    "\n",
    "SVM Method\n",
    "\n",
    "based on this example: https://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html#sphx-glr-auto-examples-svm-plot-svm-regression-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# #############################################################################\n",
    "# sample data\n",
    "X = xs_train\n",
    "y = ys_train\n",
    "\n",
    "Xt= xs_test\n",
    "\n",
    "# #############################################################################\n",
    "# Fit regression model\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.01, degree=10)\n",
    "svr_lin = SVR(kernel='linear', C=100, gamma='auto', epsilon=.1)\n",
    "svr_poly = SVR(kernel='poly', C=100, gamma='auto', degree=12, epsilon=.1,\n",
    "               coef0=1)\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Scale data<a name=\"scaleData\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(xs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train = scaler.transform(xs_train)\n",
    "xs_test = scaler.transform(xs_test)\n",
    "\n",
    "y_mean = np.mean(ys_train, axis=0)\n",
    "ys_train = ys_train/y_mean\n",
    "ys_test = ys_test/y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train emulator<a name=\"trainEmu\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_regresssion(kwargs):\n",
    "    regrs = np.empty(n_values, dtype=object)\n",
    "    scores= np.empty(n_values, dtype=object)\n",
    "    for j in range(n_values):\n",
    "        ys_train_r = ys_train[:,j]\n",
    "        ys_test_r = ys_test[:,j]\n",
    "        regr = SVR(**kwargs).fit(xs_train, ys_train_r)\n",
    "        score = regr.score(xs_test, ys_test_r)\n",
    "        print(f\"Value {j} score:\", score)\n",
    "        regrs[j] = regr\n",
    "        scores[j] = score\n",
    "    print()\n",
    "    return regrs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'kernel':'rbf', 'epsilon':5e-4, 'C':11, 'gamma':0.09,'tol':1e-6}\n",
    "r,s = do_regresssion(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrs = r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Predict on test data<a name=\"predEmu\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_predict = np.zeros((n_test, n_values))\n",
    "for j in range(n_values):  \n",
    "    ys_predict_r = regrs[j].predict(xs_test)\n",
    "    ys_predict[:,j] = ys_predict_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = int(0.2*n_test)\n",
    "idxs = np.random.choice(np.arange(n_test), n_plot)\n",
    "color_idx = np.linspace(0, 1, n_plot)\n",
    "colors = np.array([plt.cm.rainbow(c) for c in color_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_train = ys_train*y_mean\n",
    "ys_test = ys_test*y_mean\n",
    "ys_predict = ys_predict*y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Plot results<a name=\"plotEmu\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i in range(n_plot):\n",
    "    ys_test_plot = ys_test[idxs,:][i]\n",
    "    ys_predict_plot = ys_predict[idxs][i]\n",
    "    if i==0:\n",
    "        label_test = 'truth'\n",
    "        label_predict = 'emu_prediction'\n",
    "    else:\n",
    "        label_test = None\n",
    "        label_predict = None\n",
    "    plt.plot(rvals[:n_values], ys_test_plot, alpha=0.8, label=label_test, marker='o', markerfacecolor='None', ls='None', color=colors[i])\n",
    "    plt.plot(rvals[:n_values], ys_predict_plot, alpha=0.8, label=label_predict, color=colors[i])\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel(r'$\\xi(r)$')\n",
    "plt.title('SVM')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i in range(n_plot):\n",
    "    ys_test_plot = ys_test[idxs,:][i]\n",
    "    ys_predict_plot = ys_predict[idxs][i]\n",
    "    frac_err = (ys_predict_plot-ys_test_plot)/ys_test_plot\n",
    "    plt.plot(rvals, frac_err, alpha=0.8, color=colors[i])\n",
    "plt.axhline(0.0, color='k')\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel(r'fractional error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Improving the emulator<a name=\"improveEmu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a grid search to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_train = ys_train/y_mean\n",
    "ys_test = ys_test/y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which kernel is best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = make_scorer(r2_score)\n",
    "param_grid = [{'kernel': ['linear'], 'gamma': [7e-2,9e-2,11e-2],\n",
    "               'C': [ 1, 7, 10], 'epsilon':[1e-3,1e-4]},\n",
    "             {'kernel': ['poly'], 'gamma': [7e-2,9e-2,11e-2],\n",
    "               'C': [ 1, 7, 10], 'epsilon':[1e-3,1e-4]},\n",
    "             {'kernel': ['rbf'], 'gamma': [7e-2,9e-2,11e-2],\n",
    "               'C': [ 1, 7, 10], 'epsilon':[1e-3,1e-4]}]\n",
    "\n",
    "# param_grid = [{'kernel': ['rbf'], 'gamma': [7e-2,9e-2,11e-2],\n",
    "#                'C': [ 1, 3, 7, 10]}]\n",
    "\n",
    "g_cv = GridSearchCV(SVR(), param_grid, scoring=scoring, refit=True, cv=10)\n",
    "g_cv.fit(xs_train, ys_train[:,7])\n",
    "score = r2_score(ys_test[:,7], g_cv.predict(xs_test))\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print('%.5f'%score,':',g_cv.best_params_)\n",
    "print()\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = g_cv.cv_results_['mean_test_score']\n",
    "stds = g_cv.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, g_cv.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which kernel is best?\n",
    "Answer: rbf, then linear and poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the best setup for all bins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scoring = make_scorer(r2_score)\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': [5e-2,7e-2,9e-2],\n",
    "               'C': [ 7, 10, 13, 20], 'epsilon':[5e-4,1e-4,5-4]}]\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "for ix in range(n_values):\n",
    "    g_cv = GridSearchCV(SVR(), param_grid, scoring=scoring, refit=True, cv=10)\n",
    "    g_cv.fit(xs_train, ys_train[:,ix])\n",
    "    score = r2_score(ys_test[:,ix], g_cv.predict(xs_test))\n",
    "    print()\n",
    "    print('radii bin %i'%ix)\n",
    "    print('%.4f'%score,':',g_cv.best_params_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's best to use a mean value of the parameters: epsilon=0.05;\n",
    "gamma = 0.09;\n",
    "C = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
